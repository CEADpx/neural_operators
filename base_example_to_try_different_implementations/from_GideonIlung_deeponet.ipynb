{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from_GideonIlung_deeponet.ipynb\n",
    "\n",
    "The forward problem is based on Poisson equation, and the map of interest is the one that takes Dirichlet boundary condition function to the solution of the PDE. The dmain is a triangular with a notch. The numerical solution and the implementation in Matlab is from the repository [deeponet-fno](https://github.com/lu-group/deeponet-fno/tree/main).\n",
    "\n",
    "> For the implementation, we only need `Darcy_Triangulation.mat` which is included in the repository. \n",
    "\n",
    "> Dependencies can be installed using `neuralop.yml` file in the root directory of this repository. \n",
    "\n",
    "Notebook shows the implemntation of DeepONet following [DeepONet](https://github.com/GideonIlung/DeepONet) repository. We made few minor changes but the core implementation is from the mentioned source. This method uses `pytorch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7c74817d25f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/'\n",
    "result_folder = 'Results_second_method/'\n",
    "current_directory = os.getcwd()  \n",
    "results_dir = current_directory + '/' + result_folder\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axisartist.axislines import Subplot\n",
    "import matplotlib.tri as tri\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def field_plot(ax, fn_nodal_values, nodes, elements = None, dim = 2, \\\n",
    "                        add_displacement_to_nodes = False, \\\n",
    "                        is_displacement = False, \\\n",
    "                        dbg_log = False, **kwargs):\n",
    "    \n",
    "    if dim != 2:\n",
    "        raise ValueError(\"Only 2D plots are supported\")\n",
    "    \n",
    "    if dbg_log:\n",
    "        print('fn_nodal_values.shape = {}, nodes.shape = {}'.format(fn_nodal_values.shape, \\\n",
    "                                                                nodes.shape))\n",
    "    \n",
    "    n1, n2 = len(fn_nodal_values), 1\n",
    "    if fn_nodal_values.ndim == 2:\n",
    "        n2 = fn_nodal_values.shape[1]\n",
    "    elif fn_nodal_values.ndim > 2: \n",
    "        raise ValueError(\"fn_nodal_values should be a 1D or 2D array\")\n",
    "\n",
    "    if n1 != nodes.shape[0]:\n",
    "        raise ValueError(\"Number of nodes in the mesh and the number of dofs do not match\")\n",
    "    \n",
    "    # Compute magnitude of the field\n",
    "    C = None\n",
    "    if fn_nodal_values.ndim == 1:\n",
    "        C = fn_nodal_values[:]**2\n",
    "    else:\n",
    "        for i in range(n2):\n",
    "            if i == 0:\n",
    "                C = fn_nodal_values[:, i]**2\n",
    "            else:\n",
    "                C += fn_nodal_values[:, i]**2\n",
    "\n",
    "    C = np.sqrt(C)\n",
    "\n",
    "    # manipulate the configuration of the plot\n",
    "    nodes_def = nodes\n",
    "    if is_displacement:\n",
    "        if n2 != 2:\n",
    "            raise ValueError(\"Displacement should be a 2D array for dim = 2\")\n",
    "\n",
    "        if add_displacement_to_nodes:\n",
    "            nodes_def = nodes + fn_nodal_values\n",
    "\n",
    "    if dbg_log:\n",
    "        print('nodes_def.shape = {}'.format(nodes_def.shape))\n",
    "    \n",
    "    triang = None\n",
    "    if elements is not None:\n",
    "        triang = tri.Triangulation(nodes_def[:, 0], nodes_def[:, 1], elements)\n",
    "    else:\n",
    "        triang = tri.Triangulation(nodes_def[:, 0], nodes_def[:, 1])\n",
    "\n",
    "    shading = kwargs.pop(\"shading\", \"gouraud\") # or 'shading', 'flat'\n",
    "\n",
    "    cbar = ax.tripcolor(triang, C, shading=shading, **kwargs)\n",
    "\n",
    "    return cbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEncoderDecoder:\n",
    "    def __init__(self, mean, std, tol = 1.0e-9):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.tol = tol\n",
    "\n",
    "    def encoder(self, x):\n",
    "        \n",
    "        x = (x - self.mean)/(self.std + self.tol)\n",
    "        return x   \n",
    "    \n",
    "    def decoder(self, x):\n",
    "        \n",
    "        x = x*(self.std + self.tol) + self.mean\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datahandler(Dataset):\n",
    "    def __init__(self, x_branch_, x_trunk_, y_):\n",
    "\n",
    "        x_branch = self.convert_np_to_tensor(x_branch_)\n",
    "        x_trunk = self.convert_np_to_tensor(x_trunk_)\n",
    "        y = self.convert_np_to_tensor(y_)\n",
    "\n",
    "        self.x_batch = x_branch\n",
    "        self.x_trunk = x_trunk\n",
    "        self.y = y\n",
    "\n",
    "    def convert_np_to_tensor(self,array):\n",
    "        if isinstance(array, np.ndarray):\n",
    "            # Convert NumPy array to PyTorch tensor\n",
    "            tensor = torch.from_numpy(array)\n",
    "            return tensor.to(torch.float32)\n",
    "        else:\n",
    "            return array\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)  # Assuming x_batch and x_trunk have the same length as y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_batch[index,:], self.x_trunk, self.y[index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP and Network classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, depth,act):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        #the activation function#\n",
    "        self.act = act \n",
    "\n",
    "        # Input layer\n",
    "        self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(depth - 2):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        \n",
    "        # Output layer\n",
    "        self.layers.append(nn.Linear(hidden_size, num_classes))\n",
    "        \n",
    "    def forward(self, x,final_act=False):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            x = self.act(self.layers[i](x))\n",
    "        x = self.layers[-1](x)  # No activation after the last layer\n",
    "\n",
    "        if final_act == False:\n",
    "            return x\n",
    "        else:\n",
    "            return torch.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepONet(nn.Module):\n",
    "    \n",
    "    def __init__(self,n_branch:int,width:int,depth:int,p:int,act,n_trunk:int=1):\n",
    "\n",
    "        super(DeepONet, self).__init__()\n",
    "\n",
    "        #creating the branch network#\n",
    "        self.branch_net = MLP(input_size=n_branch,hidden_size=width,num_classes=p,depth=depth,act=act)\n",
    "        self.branch_net.float()\n",
    "\n",
    "        #creating the trunk network#\n",
    "        self.trunk_net = MLP(input_size=n_trunk,hidden_size=width,num_classes=p,depth=depth,act=act)\n",
    "        self.trunk_net.float()\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.ones((1,)),requires_grad=True)\n",
    "\n",
    "        # Logger\n",
    "        self.train_loss_log = []\n",
    "        self.test_loss_log = []\n",
    "    \n",
    "    def convert_np_to_tensor(self,array):\n",
    "        if isinstance(array, np.ndarray):\n",
    "            # Convert NumPy array to PyTorch tensor\n",
    "            tensor = torch.from_numpy(array)\n",
    "            return tensor.to(torch.float32)\n",
    "        else:\n",
    "            return array\n",
    "\n",
    "    \n",
    "    def forward(self, batch):\n",
    "\n",
    "        x_branch = self.convert_np_to_tensor(batch['branch_inp'])\n",
    "        x_trunk = self.convert_np_to_tensor(batch['trunk_inp'])\n",
    "        \n",
    "        branch_out = self.branch_net.forward(x_branch)\n",
    "        trunk_out = self.trunk_net.forward(x_trunk,final_act=True)\n",
    "\n",
    "        output = branch_out @ trunk_out.t() + self.bias\n",
    "        return output\n",
    "    \n",
    "    def train(self, train_data, test_data, batch_size=32, epochs = 1000, \\\n",
    "              lr:float=0.001, log=True, \\\n",
    "              loss_print_freq = 100):\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        dataset = Datahandler(train_data['branch_inp'], \\\n",
    "                              train_data['trunk_inp'], train_data['y_out'])\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True) \n",
    "\n",
    "        trunk_inp = dataset.x_trunk\n",
    "\n",
    "        test_data_tensor = {'branch_inp': self.convert_np_to_tensor(test_data['branch_inp']), \\\n",
    "                            'trunk_inp': self.convert_np_to_tensor(test_data['trunk_inp']), \\\n",
    "                            'y_out': self.convert_np_to_tensor(test_data['y_out'])}\n",
    "\n",
    "        #using standard MSE loss\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "        self.train_loss_log = np.zeros((epochs, 1))\n",
    "        self.test_loss_log = np.zeros((epochs, 1))\n",
    "\n",
    "        # Main training loop\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            train_losses = []\n",
    "            test_losses = []\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            for branch_inp, _, y_out in dataloader:\n",
    "\n",
    "                # branch_inp = branch_inp.numpy()\n",
    "                # y_out = y_out.numpy()\n",
    "\n",
    "                # print(branch_inp.shape, trunk_inp.shape, y_out.shape)\n",
    "                batch = {'branch_inp': branch_inp, 'trunk_inp': trunk_inp, 'y_out': y_out}\n",
    "                \n",
    "                #removing previous gradients#\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #forward pass through model#\n",
    "                y_pred = self.forward(batch)\n",
    "                loss = criterion(y_pred, y_out)\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                #calculate avg loss across batches#\n",
    "                train_losses.append(loss.item())\n",
    "\n",
    "                # Update parameters\n",
    "                optimizer.step()\n",
    "\n",
    "                # compute test loss\n",
    "                y_test_pred = self.forward(test_data_tensor)\n",
    "                test_loss = criterion(y_test_pred, test_data_tensor['y_out']).item()\n",
    "                test_losses.append(test_loss)\n",
    "\n",
    "            end_time = time.perf_counter()\n",
    "            epoch_time = end_time - start_time\n",
    "\n",
    "            self.train_loss_log[epoch, 0] = np.mean(train_losses)\n",
    "            self.test_loss_log[epoch, 0] = np.mean(test_losses)\n",
    "\n",
    "            if log == True and epoch % loss_print_freq == 0:\n",
    "                print('='*30)\n",
    "                print('Epoch: {:5d}, Train Loss (rel l2): {:.3e}, Test Loss (rel l2): {:.3e}, Time (sec): {:.3f}'.format(epoch, \\\n",
    "                                                  np.mean(train_losses), \\\n",
    "                                                  np.mean(test_losses), \\\n",
    "                                                  epoch_time))\n",
    "                print('='*30)\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        test_data_tensor = {'branch_inp': self.convert_np_to_tensor(test_data['branch_inp']), \\\n",
    "                            'trunk_inp': self.convert_np_to_tensor(test_data['trunk_inp']), \\\n",
    "                            'y_out': self.convert_np_to_tensor(test_data['y_out'])}\n",
    "        return self.forward(test_data_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(num_train, num_test, inp_grid_points, out_grid_points):\n",
    "    \n",
    "    data = io.loadmat(data_folder + 'Darcy_Triangular')\n",
    "    \n",
    "    xx = data['xx']\n",
    "    yy = data['yy']\n",
    "    xx = np.reshape(xx, (-1, 1))\n",
    "    yy = np.reshape(yy, (-1, 1))\n",
    "    X_trunk = np.hstack((xx, yy))\n",
    "\n",
    "    f_train = data['f_bc'][:num_train,:]\n",
    "    u_train = data['u_field'][:num_train,:]\n",
    "\n",
    "    f_test = data['f_bc'][num_train:(num_train + num_test),:]\n",
    "    u_test = data['u_field'][num_train:(num_train + num_test),:]\n",
    "\n",
    "    f_train_mean = np.mean(f_train, 0)\n",
    "    f_train_std = np.std(f_train, 0)\n",
    "    inp_decencoder = DataEncoderDecoder(f_train_mean, f_train_std)\n",
    "\n",
    "\n",
    "    u_train_mean = np.mean(u_train, 0)\n",
    "    u_train_std = np.std(u_train, 0)\n",
    "    out_decencoder = DataEncoderDecoder(u_train_mean, u_train_std)\n",
    "\n",
    "    # encode the data\n",
    "    F_train = inp_decencoder.encoder(f_train)\n",
    "    U_train = out_decencoder.encoder(u_train)\n",
    "    F_test = inp_decencoder.encoder(f_test)\n",
    "    U_test = out_decencoder.encoder(u_test)    \n",
    "\n",
    "    return data, X_trunk, F_train, U_train, F_test, U_test, inp_decencoder, out_decencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_train: (1900, 101)\n",
      "U_train: (1900, 2397)\n",
      "F_test: (100, 101)\n",
      "U_test: (100, 2397)\n",
      "X_trunk: (2397, 2)\n"
     ]
    }
   ],
   "source": [
    "num_train = 1900\n",
    "num_test = 100\n",
    "\n",
    "inp_grid_points = 101 # number of grid points for the input function\n",
    "out_grid_points = 2397 # number of evaluations points for the output function\n",
    "num_br_tr_outputs = 100 # number of outputs from the branch and trunk networks before they are multiplied\n",
    "\n",
    "data, X_trunk, F_train, U_train, F_test, U_test, inp_decencoder, \\\n",
    "    out_decencoder = process_data(num_train, num_test, inp_grid_points, out_grid_points)\n",
    "\n",
    "train_data = {'branch_inp': F_train, 'trunk_inp': X_trunk, 'y_out': U_train}\n",
    "test_data = {'branch_inp': F_test, 'trunk_inp': X_trunk, 'y_out': U_test}\n",
    "\n",
    "print('F_train:',F_train.shape)\n",
    "print('U_train:',U_train.shape)\n",
    "print('F_test:',F_test.shape)\n",
    "print('U_test:',U_test.shape)\n",
    "print('X_trunk:',X_trunk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "layer_width = 128\n",
    "model = DeepONet(n_branch = inp_grid_points, n_trunk = 2, \\\n",
    "                 width = layer_width, depth = num_layers, \\\n",
    "                 p = num_br_tr_outputs, \\\n",
    "                 act=torch.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Epoch:     0, Train Loss (rel l2): 9.324e-01, Test Loss (rel l2): 8.782e-01, Time (sec): 0.269\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   100, Train Loss (rel l2): 4.514e-03, Test Loss (rel l2): 4.845e-03, Time (sec): 0.205\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Create data set\n",
    "batch_size = 100\n",
    "epochs = 10000\n",
    "lr = 1.0e-3\n",
    "\n",
    "# Train\n",
    "model.train(train_data, test_data, batch_size=batch_size, epochs = epochs, lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the loss history\n",
    "num_epoch = model.train_loss_log.shape[0]\n",
    "x = np.linspace(1, num_epoch, num_epoch)\n",
    "fig = plt.figure(constrained_layout=False, figsize=(6, 6))\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "ax = fig.add_subplot(gs[0])\n",
    "ax.plot(x, model.train_loss_log[:, 0], color='blue', label='Training Loss')\n",
    "ax.plot(x, model.test_loss_log[:, 0], color='red', label='Testing Loss')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.legend(loc='best')\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_dir+'loss_his.png',  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and plot the output of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out = test_data['y_out']\n",
    "test_pred = model.predict(test_data).detach().numpy()\n",
    "\n",
    "print('test_out shape: {}, test_pred shape: {}'.format(test_out.shape, test_pred.shape))\n",
    "\n",
    "error = np.linalg.norm(test_out - test_pred, axis = 1)/np.linalg.norm(test_out, axis = 1)\n",
    "\n",
    "print('Num tests: {:5d}, Mean Loss (rel l2): {:.3e}, Std Loss (rel l2): {:.3e}'.format(num_test, np.mean(error), np.std(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 4, 4\n",
    "fs = 20\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(16, 16))\n",
    "\n",
    "decode = True\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        i_plot = i*cols + j\n",
    "\n",
    "        i_pred = test_pred[i_plot, :]\n",
    "        i_truth = test_out[i_plot, :]\n",
    "        if decode:\n",
    "            i_pred = out_decencoder.decoder(i_pred)\n",
    "            i_truth = out_decencoder.decoder(i_truth)\n",
    "\n",
    "        i_diff = i_pred - i_truth\n",
    "        i_diff_norm = np.linalg.norm(i_diff) / np.linalg.norm(i_truth)\n",
    "        print('i_plot = {:5d}, error (rel l2): {:.3e}'.format(i_plot, i_diff_norm))\n",
    "\n",
    "        nodes = X_trunk\n",
    "\n",
    "        cbar = field_plot(axs[i,j], i_diff, nodes)\n",
    "\n",
    "        divider = make_axes_locatable(axs[i,j])\n",
    "        cax = divider.append_axes('right', size='8%', pad=0.03)\n",
    "        cax.tick_params(labelsize=fs)\n",
    "        fig.colorbar(cbar, cax=cax, orientation='vertical')\n",
    "\n",
    "        axs[j,i].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Error in the solution field', fontsize=1.5*fs, y=1.025)\n",
    "fig.savefig(results_dir+'sample_error_plots.png',  bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
