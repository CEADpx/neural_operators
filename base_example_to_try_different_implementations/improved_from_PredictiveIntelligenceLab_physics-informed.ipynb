{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improved_from_PredictiveIntelligenceLab_physics-informed.ipynb\n",
    "\n",
    "The forward problem is based on Poisson equation, and the map of interest is the one that takes Dirichlet boundary condition function to the solution of the PDE. The dmain is a triangular with a notch. The numerical solution and the implementation in Matlab is from the repository [deeponet-fno](https://github.com/lu-group/deeponet-fno/tree/main).\n",
    "\n",
    "> For the implementation, we only need `Darcy_Triangulation.mat` which is included in the repository. \n",
    "\n",
    "> Dependencies can be installed using `neuralop.yml` file in the root directory of this repository. \n",
    "\n",
    "Notebook [implements DeepONet following [Physics-informed-DeepONets](https://github.com/PredictiveIntelligenceLab/Physics-informed-DeepONets/tree/main) library. This is based on `jax`. The original implementation is buggy and data intensive. It needs data in the form of $(N*P) \\times M$ for branch input, $(N*P)\\times 2$ for trunk input, and $(N*P) \\times 1$ for output, where\n",
    "- $N$ - Number of input functions\n",
    "- $M$ - Number of elements in one input function (number of nodal values after the discretization of input function)\n",
    "- $P$ - Number of spatial points in 2D at which the output function is evaluated. \n",
    "In our case, $N = 1900$ = number of training input functions, $M = 101$ = elements in discretization of one input function, and $P=2397$ = nodes in the finite element mesh of the domain which are also used as spatial locations to evaluate the output function. With these numbers, the size of data is pretty large. The workstation with 64 Gb ram could not handle the code, and could not finish even a single optimization step.\n",
    "\n",
    "In the current implementation, we use the data as in the first two implementation, and the code is quite fast in training and memory efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x79883c3d2a70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "from jax import random, grad, vmap, jit\n",
    "from jax.example_libraries import optimizers\n",
    "from jax.experimental.ode import odeint\n",
    "from jax.nn import relu\n",
    "from jax.config import config\n",
    "from jax.flatten_util import ravel_pytree\n",
    "\n",
    "import itertools\n",
    "from functools import partial\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.io as io\n",
    "\n",
    "# set seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data/'\n",
    "result_folder = 'Results_third_method/'\n",
    "current_directory = os.getcwd()  \n",
    "save_results_to = current_directory + '/' + result_folder\n",
    "if not os.path.exists(save_results_to):\n",
    "    os.makedirs(save_results_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axisartist.axislines import Subplot\n",
    "import matplotlib.tri as tri\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def field_plot(ax, fn_nodal_values, nodes, elements = None, dim = 2, \\\n",
    "                        add_displacement_to_nodes = False, \\\n",
    "                        is_displacement = False, \\\n",
    "                        dbg_log = False, **kwargs):\n",
    "    \n",
    "    if dim != 2:\n",
    "        raise ValueError(\"Only 2D plots are supported\")\n",
    "    \n",
    "    if dbg_log:\n",
    "        print('fn_nodal_values.shape = {}, nodes.shape = {}'.format(fn_nodal_values.shape, \\\n",
    "                                                                nodes.shape))\n",
    "    \n",
    "    n1, n2 = len(fn_nodal_values), 1\n",
    "    if fn_nodal_values.ndim == 2:\n",
    "        n2 = fn_nodal_values.shape[1]\n",
    "    elif fn_nodal_values.ndim > 2: \n",
    "        raise ValueError(\"fn_nodal_values should be a 1D or 2D array\")\n",
    "\n",
    "    if n1 != nodes.shape[0]:\n",
    "        raise ValueError(\"Number of nodes in the mesh and the number of dofs do not match\")\n",
    "    \n",
    "    # Compute magnitude of the field\n",
    "    C = None\n",
    "    if fn_nodal_values.ndim == 1:\n",
    "        C = fn_nodal_values[:]**2\n",
    "    else:\n",
    "        for i in range(n2):\n",
    "            if i == 0:\n",
    "                C = fn_nodal_values[:, i]**2\n",
    "            else:\n",
    "                C += fn_nodal_values[:, i]**2\n",
    "\n",
    "    C = np.sqrt(C)\n",
    "\n",
    "    # manipulate the configuration of the plot\n",
    "    nodes_def = nodes\n",
    "    if is_displacement:\n",
    "        if n2 != 2:\n",
    "            raise ValueError(\"Displacement should be a 2D array for dim = 2\")\n",
    "\n",
    "        if add_displacement_to_nodes:\n",
    "            nodes_def = nodes + fn_nodal_values\n",
    "\n",
    "    if dbg_log:\n",
    "        print('nodes_def.shape = {}'.format(nodes_def.shape))\n",
    "    \n",
    "    triang = None\n",
    "    if elements is not None:\n",
    "        triang = tri.Triangulation(nodes_def[:, 0], nodes_def[:, 1], elements)\n",
    "    else:\n",
    "        triang = tri.Triangulation(nodes_def[:, 0], nodes_def[:, 1])\n",
    "\n",
    "    shading = kwargs.pop(\"shading\", \"gouraud\") # or 'shading', 'flat'\n",
    "\n",
    "    cbar = ax.tripcolor(triang, C, shading=shading, **kwargs)\n",
    "\n",
    "    return cbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEncoderDecoder:\n",
    "    def __init__(self, mean, std, tol = 1.0e-9):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.tol = tol\n",
    "\n",
    "    def encoder(self, x):\n",
    "        \n",
    "        x = (x - self.mean)/(self.std + self.tol)\n",
    "        return x   \n",
    "    \n",
    "    def decoder(self, x):\n",
    "        \n",
    "        x = x*(self.std + self.tol) + self.mean\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datahandler(Dataset):\n",
    "    def __init__(self, x_branch_, x_trunk_, y_):\n",
    "\n",
    "        # x_branch = self.convert_np_to_tensor(x_branch_)\n",
    "        # x_trunk = self.convert_np_to_tensor(x_trunk_)\n",
    "        # y = self.convert_np_to_tensor(y_)\n",
    "\n",
    "        self.x_batch = x_branch_\n",
    "        self.x_trunk = x_trunk_\n",
    "        self.y = y_\n",
    "\n",
    "    def convert_np_to_tensor(self,array):\n",
    "        if isinstance(array, np.ndarray):\n",
    "            # Convert NumPy array to PyTorch tensor\n",
    "            tensor = torch.from_numpy(array)\n",
    "            return tensor.to(torch.float32)\n",
    "        else:\n",
    "            return array\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)  # Assuming x_batch and x_trunk have the same length as y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_batch[index,:], self.x_trunk, self.y[index,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP and Network classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural net\n",
    "def MLP(layers, activation=relu):\n",
    "  ''' Vanilla MLP'''\n",
    "  def init(rng_key):\n",
    "      def init_layer(key, d_in, d_out):\n",
    "          k1, k2 = random.split(key)\n",
    "          glorot_stddev = 1. / jnp.sqrt((d_in + d_out) / 2.)\n",
    "          W = glorot_stddev * random.normal(k1, (d_in, d_out))\n",
    "          b = jnp.zeros(d_out)\n",
    "          return W, b\n",
    "      key, *keys = random.split(rng_key, len(layers))\n",
    "      params = list(map(init_layer, keys, layers[:-1], layers[1:]))\n",
    "      return params\n",
    "  def apply(params, inputs):\n",
    "      for W, b in params[:-1]:\n",
    "          outputs = jnp.dot(inputs, W) + b\n",
    "          inputs = activation(outputs)\n",
    "      W, b = params[-1]\n",
    "      outputs = jnp.dot(inputs, W) + b\n",
    "      return outputs\n",
    "  return init, apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class DeepONet:\n",
    "    def __init__(self, branch_layers, trunk_layers, lr = 1.e-3):    \n",
    "        # Network initialization and evaluation functions\n",
    "        self.branch_init, self.branch_apply = MLP(branch_layers, activation=relu)\n",
    "        self.trunk_init, self.trunk_apply = MLP(trunk_layers, activation=relu)\n",
    "\n",
    "        # Initialize\n",
    "        branch_params = self.branch_init(rng_key = random.PRNGKey(1234))\n",
    "        trunk_params = self.trunk_init(rng_key = random.PRNGKey(4321))\n",
    "        params = (branch_params, trunk_params)\n",
    "\n",
    "        # Use optimizers to set optimizer initialization and update functions\n",
    "        self.opt_init, \\\n",
    "        self.opt_update, \\\n",
    "        self.get_params = optimizers.adam(optimizers.exponential_decay(lr, \n",
    "                                                                      decay_steps=2000, \n",
    "                                                                      decay_rate=0.9))\n",
    "        self.opt_state = self.opt_init(params)\n",
    "\n",
    "        # Used to restore the trained model parameters\n",
    "        _, self.unravel_params = ravel_pytree(params)\n",
    "\n",
    "        self.itercount = itertools.count()\n",
    "        # Logger\n",
    "        self.train_loss_log = []\n",
    "        self.test_loss_log = []\n",
    "\n",
    "    # Define opeartor net\n",
    "    def operator_net(self, params, branch_inp, trunk_inp):\n",
    "        branch_params, trunk_params = params\n",
    "        B = self.branch_apply(branch_params, branch_inp)\n",
    "        T = self.trunk_apply(trunk_params, trunk_inp)\n",
    "        outputs = jnp.dot(B, T.T)\n",
    "        # print('B shape: {}, T shape: {}, outputs shape: {}'.format(B.shape, T.shape, outputs.shape))\n",
    "        return outputs\n",
    "    \n",
    "    # Define operator loss\n",
    "    def loss_operator(self, params, batch):\n",
    "        branch_inp = batch['branch_inp']\n",
    "        trunk_inp = batch['trunk_inp']\n",
    "        y_out = batch['y_out']\n",
    "        \n",
    "        # Compute forward pass\n",
    "        # s_pred = vmap(self.operator_net, (None, 0, 0))(params, branch_inp, trunk_inp)\n",
    "        s_pred = self.operator_net(params, branch_inp, trunk_inp)\n",
    "        \n",
    "        # Compute y_out\n",
    "        loss = jnp.mean((y_out.flatten() - s_pred.flatten())**2)\n",
    "        return loss\n",
    "    \n",
    "    # Define a compiled update step\n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def step(self, i, opt_state, batch):\n",
    "        params = self.get_params(opt_state)\n",
    "        g = grad(self.loss_operator)(params, batch)\n",
    "        return self.opt_update(i, g, opt_state)\n",
    "\n",
    "    # Optimize parameters in a loop\n",
    "    def train(self, train_data, test_data, batch_size=32, epochs=100, \\\n",
    "              log=True, loss_print_freq = 100):\n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        dataset = Datahandler(train_data['branch_inp'], \\\n",
    "                              train_data['trunk_inp'], train_data['y_out'])\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        trunk_inp = dataset.x_trunk\n",
    "\n",
    "        self.train_loss_log = np.zeros((epochs, 1))\n",
    "        self.test_loss_log = np.zeros((epochs, 1))\n",
    "        \n",
    "        # Main training loop\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            train_losses = []\n",
    "            test_losses = []\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "\n",
    "            for branch_inp, _, y_out in dataloader:\n",
    "                branch_inp = branch_inp.numpy()\n",
    "                y_out = y_out.numpy()\n",
    "\n",
    "                # print(branch_inp.shape, trunk_inp.shape, y_out.shape)\n",
    "\n",
    "                batch = {'branch_inp': branch_inp, 'trunk_inp': trunk_inp, 'y_out': y_out}\n",
    "\n",
    "                self.opt_state = self.step(next(self.itercount), \\\n",
    "                                           self.opt_state, batch)\n",
    "                \n",
    "                # train loss\n",
    "                params = self.get_params(self.opt_state)\n",
    "                train_losses.append(self.loss_operator(params, batch))\n",
    "\n",
    "                # test loss\n",
    "                test_losses.append(self.loss_operator(params, test_data))\n",
    "\n",
    "            end_time = time.perf_counter()\n",
    "            epoch_time = end_time - start_time\n",
    "\n",
    "            self.train_loss_log[epoch, 0] = np.mean(train_losses)\n",
    "            self.test_loss_log[epoch, 0] = np.mean(test_losses)\n",
    "\n",
    "            if log == True and epoch % loss_print_freq == 0:\n",
    "                print('='*30)\n",
    "                print('Epoch: {:5d}, Train Loss (rel l2): {:.3e}, Test Loss (rel l2): {:.3e}, Time (sec): {:.3f}'.format(epoch, \\\n",
    "                                                  np.mean(train_losses), \\\n",
    "                                                  np.mean(test_losses), \\\n",
    "                                                  epoch_time))\n",
    "                print('='*30)\n",
    "       \n",
    "    # Evaluates predictions at test points  \n",
    "    @partial(jit, static_argnums=(0,))\n",
    "    def predict_s(self, params, branch_inp, trunk_inp):\n",
    "        s_pred = self.operator_net(params, branch_inp, trunk_inp)\n",
    "        return s_pred\n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        branch_inp = test_data['branch_inp']\n",
    "        trunk_inp = test_data['trunk_inp']\n",
    "        y_out = test_data['y_out']\n",
    "\n",
    "        params = self.get_params(self.opt_state)\n",
    "        y_pred = self.operator_net(params, branch_inp, trunk_inp)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(num_train, num_test, inp_grid_points, out_grid_points):\n",
    "    \n",
    "    data = io.loadmat(data_folder + 'Darcy_Triangular')\n",
    "    \n",
    "    xx = data['xx']\n",
    "    yy = data['yy']\n",
    "    xx = np.reshape(xx, (-1, 1))\n",
    "    yy = np.reshape(yy, (-1, 1))\n",
    "    X_trunk = np.hstack((xx, yy))\n",
    "\n",
    "    f_train = data['f_bc'][:num_train,:]\n",
    "    u_train = data['u_field'][:num_train,:]\n",
    "\n",
    "    f_test = data['f_bc'][num_train:(num_train + num_test),:]\n",
    "    u_test = data['u_field'][num_train:(num_train + num_test),:]\n",
    "\n",
    "    f_train_mean = np.mean(f_train, 0)\n",
    "    f_train_std = np.std(f_train, 0)\n",
    "    inp_decencoder = DataEncoderDecoder(f_train_mean, f_train_std)\n",
    "\n",
    "\n",
    "    u_train_mean = np.mean(u_train, 0)\n",
    "    u_train_std = np.std(u_train, 0)\n",
    "    out_decencoder = DataEncoderDecoder(u_train_mean, u_train_std)\n",
    "\n",
    "    # encode the data\n",
    "    F_train = inp_decencoder.encoder(f_train)\n",
    "    U_train = out_decencoder.encoder(u_train)\n",
    "    F_test = inp_decencoder.encoder(f_test)\n",
    "    U_test = out_decencoder.encoder(u_test)    \n",
    "\n",
    "    return data, X_trunk, F_train, U_train, F_test, U_test, inp_decencoder, out_decencoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_train: (1900, 101)\n",
      "U_train: (1900, 2397)\n",
      "F_test: (100, 101)\n",
      "U_test: (100, 2397)\n",
      "X_trunk: (2397, 2)\n"
     ]
    }
   ],
   "source": [
    "num_train = 1900\n",
    "num_test = 100\n",
    "\n",
    "inp_grid_points = 101 # number of grid points for the input function\n",
    "out_grid_points = 2397 # number of evaluations points for the output function\n",
    "num_br_tr_outputs = 100 # number of outputs from the branch and trunk networks before they are multiplied\n",
    "\n",
    "data, X_trunk, F_train, U_train, F_test, U_test, inp_decencoder, \\\n",
    "    out_decencoder = process_data(num_train, num_test, inp_grid_points, out_grid_points)\n",
    "\n",
    "train_data = {'branch_inp': F_train, 'trunk_inp': X_trunk, 'y_out': U_train}\n",
    "test_data = {'branch_inp': F_test, 'trunk_inp': X_trunk, 'y_out': U_test}\n",
    "\n",
    "print('F_train:',F_train.shape)\n",
    "print('U_train:',U_train.shape)\n",
    "print('F_test:',F_test.shape)\n",
    "print('U_test:',U_test.shape)\n",
    "print('X_trunk:',X_trunk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1730682402.008844   89084 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.\n",
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "branch_layers = [inp_grid_points, 128, 128, num_br_tr_outputs]\n",
    "trunk_layers =  [2, 128, 128, num_br_tr_outputs]\n",
    "lr = 1.e-3\n",
    "\n",
    "model = DeepONet(branch_layers, trunk_layers, lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "Epoch:     0, Train Loss (rel l2): 4.311e-01, Test Loss (rel l2): 4.437e-01, Time (sec): 1.800\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   100, Train Loss (rel l2): 1.368e-02, Test Loss (rel l2): 1.616e-02, Time (sec): 0.709\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   200, Train Loss (rel l2): 5.598e-03, Test Loss (rel l2): 6.025e-03, Time (sec): 0.692\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   300, Train Loss (rel l2): 2.755e-03, Test Loss (rel l2): 3.117e-03, Time (sec): 0.725\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   400, Train Loss (rel l2): 1.751e-03, Test Loss (rel l2): 2.053e-03, Time (sec): 0.707\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   500, Train Loss (rel l2): 1.340e-03, Test Loss (rel l2): 1.594e-03, Time (sec): 0.728\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   600, Train Loss (rel l2): 1.037e-03, Test Loss (rel l2): 1.204e-03, Time (sec): 0.717\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   700, Train Loss (rel l2): 7.924e-04, Test Loss (rel l2): 9.470e-04, Time (sec): 0.702\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   800, Train Loss (rel l2): 5.784e-04, Test Loss (rel l2): 6.964e-04, Time (sec): 0.569\n",
      "==============================\n",
      "==============================\n",
      "Epoch:   900, Train Loss (rel l2): 1.404e-03, Test Loss (rel l2): 1.595e-03, Time (sec): 0.684\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1000, Train Loss (rel l2): 9.185e-04, Test Loss (rel l2): 1.043e-03, Time (sec): 0.577\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1100, Train Loss (rel l2): 4.640e-04, Test Loss (rel l2): 5.447e-04, Time (sec): 0.692\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1200, Train Loss (rel l2): 2.861e-04, Test Loss (rel l2): 3.385e-04, Time (sec): 0.679\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1300, Train Loss (rel l2): 2.350e-04, Test Loss (rel l2): 2.771e-04, Time (sec): 0.664\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1400, Train Loss (rel l2): 1.679e-03, Test Loss (rel l2): 1.831e-03, Time (sec): 0.696\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1500, Train Loss (rel l2): 1.847e-04, Test Loss (rel l2): 2.146e-04, Time (sec): 0.712\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1600, Train Loss (rel l2): 5.158e-04, Test Loss (rel l2): 5.763e-04, Time (sec): 0.553\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1700, Train Loss (rel l2): 1.828e-04, Test Loss (rel l2): 2.074e-04, Time (sec): 0.713\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1800, Train Loss (rel l2): 1.432e-04, Test Loss (rel l2): 1.635e-04, Time (sec): 0.755\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  1900, Train Loss (rel l2): 1.321e-04, Test Loss (rel l2): 1.504e-04, Time (sec): 0.557\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2000, Train Loss (rel l2): 1.247e-04, Test Loss (rel l2): 1.424e-04, Time (sec): 0.637\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2100, Train Loss (rel l2): 1.199e-04, Test Loss (rel l2): 1.362e-04, Time (sec): 0.701\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2200, Train Loss (rel l2): 1.326e-04, Test Loss (rel l2): 1.488e-04, Time (sec): 0.718\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2300, Train Loss (rel l2): 1.010e-04, Test Loss (rel l2): 1.137e-04, Time (sec): 0.714\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2400, Train Loss (rel l2): 9.591e-05, Test Loss (rel l2): 1.080e-04, Time (sec): 0.638\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2500, Train Loss (rel l2): 1.041e-04, Test Loss (rel l2): 1.175e-04, Time (sec): 0.562\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2600, Train Loss (rel l2): 8.732e-05, Test Loss (rel l2): 9.745e-05, Time (sec): 0.760\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2700, Train Loss (rel l2): 8.652e-05, Test Loss (rel l2): 9.722e-05, Time (sec): 0.704\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2800, Train Loss (rel l2): 8.139e-05, Test Loss (rel l2): 9.074e-05, Time (sec): 0.676\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  2900, Train Loss (rel l2): 8.500e-05, Test Loss (rel l2): 9.432e-05, Time (sec): 0.699\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3000, Train Loss (rel l2): 7.731e-05, Test Loss (rel l2): 8.612e-05, Time (sec): 0.718\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3100, Train Loss (rel l2): 7.590e-05, Test Loss (rel l2): 8.427e-05, Time (sec): 0.602\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3200, Train Loss (rel l2): 7.324e-05, Test Loss (rel l2): 8.147e-05, Time (sec): 0.589\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3300, Train Loss (rel l2): 7.179e-05, Test Loss (rel l2): 7.979e-05, Time (sec): 0.688\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3400, Train Loss (rel l2): 7.002e-05, Test Loss (rel l2): 7.789e-05, Time (sec): 1.131\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3500, Train Loss (rel l2): 6.795e-05, Test Loss (rel l2): 7.538e-05, Time (sec): 1.160\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3600, Train Loss (rel l2): 6.795e-05, Test Loss (rel l2): 7.535e-05, Time (sec): 1.185\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3700, Train Loss (rel l2): 6.563e-05, Test Loss (rel l2): 7.275e-05, Time (sec): 1.183\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3800, Train Loss (rel l2): 6.452e-05, Test Loss (rel l2): 7.140e-05, Time (sec): 1.189\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  3900, Train Loss (rel l2): 6.406e-05, Test Loss (rel l2): 7.114e-05, Time (sec): 1.228\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  4000, Train Loss (rel l2): 6.271e-05, Test Loss (rel l2): 6.941e-05, Time (sec): 1.233\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  4100, Train Loss (rel l2): 6.120e-05, Test Loss (rel l2): 6.776e-05, Time (sec): 0.709\n",
      "==============================\n",
      "==============================\n",
      "Epoch:  4200, Train Loss (rel l2): 6.061e-05, Test Loss (rel l2): 6.708e-05, Time (sec): 0.716\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Create data set\n",
    "batch_size = 100\n",
    "epochs = 10000\n",
    "\n",
    "# Train\n",
    "model.train(train_data, test_data, batch_size=batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the loss history\n",
    "num_epoch = model.train_loss_log.shape[0]\n",
    "x = np.linspace(1, num_epoch, num_epoch)\n",
    "fig = plt.figure(constrained_layout=False, figsize=(6, 6))\n",
    "gs = fig.add_gridspec(1, 1)\n",
    "ax = fig.add_subplot(gs[0])\n",
    "ax.plot(x, model.train_loss_log[:, 0], color='blue', label='Training Loss')\n",
    "ax.plot(x, model.test_loss_log[:, 0], color='red', label='Testing Loss')\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.legend(loc='best')\n",
    "fig.tight_layout()\n",
    "fig.savefig(save_results_to+'loss_his.png',  bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and plot the output of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternatively, use class method to predict\n",
    "test_out = test_data['y_out']\n",
    "test_pred = model.predict(test_data)\n",
    "\n",
    "print('test_out shape: {}, test_pred shape: {}'.format(test_out.shape, test_pred.shape))\n",
    "\n",
    "error = np.linalg.norm(test_out - test_pred, axis = 1)/np.linalg.norm(test_out, axis = 1)\n",
    "\n",
    "print('Num tests: {:5d}, Mean Loss (rel l2): {:.3e}, Std Loss (rel l2): {:.3e}'.format(num_test, np.mean(error), np.std(error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 4, 4\n",
    "fs = 20\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(16, 16))\n",
    "\n",
    "decode = True\n",
    "\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        i_plot = i*cols + j\n",
    "\n",
    "        i_pred = test_pred[i_plot, :]\n",
    "        i_truth = test_out[i_plot, :]\n",
    "        if decode:\n",
    "            i_pred = out_decencoder.decoder(i_pred)\n",
    "            i_truth = out_decencoder.decoder(i_truth)\n",
    "\n",
    "        i_diff = i_pred - i_truth\n",
    "        i_diff_norm = np.linalg.norm(i_diff) / np.linalg.norm(i_truth)\n",
    "        print('i_plot = {:5d}, error (rel l2): {:.3e}'.format(i_plot, i_diff_norm))\n",
    "\n",
    "        nodes = X_trunk\n",
    "\n",
    "        cbar = field_plot(axs[i,j], i_diff, nodes)\n",
    "\n",
    "        divider = make_axes_locatable(axs[i,j])\n",
    "        cax = divider.append_axes('right', size='8%', pad=0.03)\n",
    "        cax.tick_params(labelsize=fs)\n",
    "        fig.colorbar(cbar, cax=cax, orientation='vertical')\n",
    "\n",
    "        axs[j,i].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Error in the solution field', fontsize=1.5*fs, y=1.025)\n",
    "fig.savefig(save_results_to+'sample_error_plots.png',  bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
